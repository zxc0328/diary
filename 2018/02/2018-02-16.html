<!DOCTYPE html><!--[if lte IE 8]>
<html lang="en" class="lte-ie8">
<![endif]-->
<!--[if gt IE 8]><!-->
<html lang="en">
<!--<![endif]--><head><meta charset="utf-8"><title>February 16, 2018</title><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/diary/styles/global.css"><link rel="stylesheet" href="/diary/styles/tomorrow.css"><link rel="stylesheet" href="/diary/styles/diary.css"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-63818301-1', 'auto');
ga('send', 'pageview');</script></head><body><header class="header"><div class="index"><a href="/diary/">Index</a></div><h1>February 16, 2018</h1></header><div class="content"><div class="diary"><h2 id="-kubernetes-">《Kubernetes权威指南》速览总结</h2>
<h3 id="deploymentsreplicaset">Deployments&amp;&amp;ReplicaSet</h3>
<p>K8s的Workload分Pods和Controllers两种。Pod是最主要的Workload。Pod包含了一个或多个容器，是调度的最小单元。Controllers则控制Pod。Controllers里面最常用的是Deployments和ReplicaSet。而Deployments则是ReplicaSet的一个封装。我们在使用K8s时主要打交道的还是Deployments。</p>
<h3 id="rolling-update">Rolling Update</h3>
<p>我们经常需要更新deployment，比如更新其中的image。deployment的更新有两种策略，rollingupdate和recreate。在生产环境，我们希望可以达到zero downtime。因此deployment的默认更新策略是rollingupdate。</p>
<p>rollingupdate的具体实施过程是，创建一个新的replica set。然后一边提升这个replica set的replica数量。一边降低老replica set的replica set。最后老的replica set的Pod数量为0，新的replica set的Pod数量达到
deployment的预期值，更新完成。</p>
<p>因为更新中会出现可用Pod数小于预期，以及创建的所有Pod数量大于预期数量的情况，这里要引入两个参数。一个是<code>maxUnavailable</code>，一个是<code>maxSurge</code>。<code>maxUnavailable</code>是指更新过程中最大的不可用replica数量。<code>maxSurge</code>是新老replica set的Pod数之和与预期的Pod数量之间的差值。</p>
<p><code>maxUnavailable</code>和<code>maxSurge</code>现在默认值都是预期Pod副本数量的25%。注意这个数量是向上取整的。</p>
<p>如果replica是1，那么<code>maxUnavailable</code>也为1，这种情况下是会出现服务无法访问的情况的。解决办法是把replica设置为至少两个。或许也可以把<code>maxUnavailable</code>设置为0。这个需要实际尝试一下。</p>
<h3 id="configmap">ConfigMap</h3>
<p>我们在容器中经常经常遇到需要注入环境变量的情况，如果把环境变量写在deployment的定义中，就会造成耦合。我们可以把环境变量配置写成configmap，为不同的部署环境建立不同的configmap实例，然后在deployment定义中引用特定的configmap。这样我们就可以达到配置和部署的分离，便于更好的管理集群。</p>
<h3 id="label-selector-">Label Selector的使用</h3>
<p>K8s中的各种资源，都可以被打上不同的Label。Node、Pods、Deployment等等各种资源，都可以打上标签。这些标签可以是版本、环境、架构、分区等等方面的。K8s支持强大的使用Expression来选择资源的功能。这方面在运维上可以说有很大的空间。</p>
<h3 id="pod-">Pod调度</h3>
<p>我们可以通过一些设置，来影响K8s的Pod调度。这方面有<code>NodeSelector</code>、<code>NodeAffinity</code>、<code>PodAffinity</code>等等。可以根据实际的情况来进行不同的组合。在一个大集群中，不能的节点有不同的特点，通常我们会根据这些特点来进行针对性的Pod调度。</p>
<h3 id="ingress">Ingress</h3>
<p>目前木犀的k8s集群中，我们用一个单独的Nginx服务作为集群的API Gateway。Nginx的作用就是一个七层路由。但其实K8s本来就支持Ingress这种类型的服务。Ingress服务有不同的backend，可以由云服务商提供，也是可以和Nginx直接整合的。可以配置路由、SSL等等。</p>
<h3 id="k8s-">k8s原理</h3>
<p>这一章的内容解决的问题是：</p>
<ul>
<li><p>k8s是如何schedule一个pod的？</p>
</li>
<li><p>kubelet proxy的原理是什么？</p>
</li>
<li><p>service的iptable均衡负载的原理是什么</p>
</li>
<li><p>k8s的网络模型是什么？pod、service、node之间的通信分别是如何实现的？</p>
</li>
</ul>
</div></div><footer class="footer"><address class="author">Copyright &copy;<a rel="author" href="https://github.com/joyeecheung" class="author-name">Joyee Cheung</a>-<a href="https://github.com/zxc0328/diary-content.git" class="source-repo">Source</a></address><p>Generated by<a href="https://github.com/joyeecheung/diary" class="site-repo">Joyee Cheung&#39;s diary generator</a></p></footer></body></html>